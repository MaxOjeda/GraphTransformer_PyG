{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm5mDNoNcMiJ",
        "outputId": "5625c8e8-dffe-41d3-c7ca-b21be4179464"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# torchversion = torch.__version__\n",
        "\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "utN67SzJcQMp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader.dataloader import DataLoader\n",
        "from torch_geometric.datasets import ZINC\n",
        "from models.GraphTansformerNet import GraphTransformerNet\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch_geometric.transforms import AddLaplacianEigenvectorPE\n",
        "import torch_geometric.transforms as T\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxKDvjjAduir"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[29, 1], edge_index=[2, 64], edge_attr=[64], y=[1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader.dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RTU86ggKcT47"
      },
      "outputs": [],
      "source": [
        "def train(epoch, loss_func):\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "    #for data in tqdm(train_loader, desc=\"Training Loader\"):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(x=data.x.float(), edge_index=data.edge_index, edge_attr=data.edge_attr.unsqueeze(1).float(),\n",
        "                    pe=data.laplacian_eigenvector_pe, batch=data.batch)\n",
        "        loss = criterion(out.squeeze(), data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_mae = mean_absolute_error(data.y.cpu().detach().numpy(), out.squeeze().cpu().detach().numpy())\n",
        "    return loss, train_mae\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    for data in loader:\n",
        "    #for data in tqdm(loader, desc=\"Test Loader\"):\n",
        "        data = data.to(device)\n",
        "\n",
        "        out = model(x=data.x.float(), edge_index=data.edge_index, edge_attr=data.edge_attr.unsqueeze(1).float(),\n",
        "                    pe=data.laplacian_eigenvector_pe, batch=data.batch)\n",
        "        loss = criterion(out.squeeze(), data.y)\n",
        "        test_mae = mean_absolute_error(data.y.cpu().detach().numpy(), out.squeeze().cpu().detach().numpy())\n",
        "    return loss, test_mae\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Lenovo\\anaconda3\\envs\\graphgps\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data(x=[231664, 1], edge_index=[2, 498558], edge_attr=[498558], y=[10000], laplacian_eigenvector_pe=[231664, 50])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y0g-12YcWsK",
        "outputId": "f771fb3d-4b4e-4c69-88d2-1740560697ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Lenovo\\anaconda3\\envs\\graphgps\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train graphs: 10000\n",
            "Val graphs: 1000\n",
            "Test graphs: 1000\n",
            "\n",
            "GraphTransformerNet(\n",
            "  (node_emb): Linear(in_features=1, out_features=64, bias=False)\n",
            "  (edge_emb): Linear(in_features=1, out_features=64, bias=False)\n",
            "  (pe_emb): Linear(in_features=64, out_features=64, bias=False)\n",
            "  (layers): ModuleList(\n",
            "    (0-9): 10 x GraphTransformerLayer()\n",
            "  )\n",
            "  (global_pool): MultiAggregation([\n",
            "    SumAggregation(),\n",
            "  ], mode=cat)\n",
            "  (in_feat_dropout): Dropout(p=0.0, inplace=False)\n",
            "  (mlp_readout): MLPReadout(\n",
            "    (FC_layers): ModuleList(\n",
            "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
            "      (1): Linear(in_features=32, out_features=16, bias=True)\n",
            "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total de parámetros en el modelo: 590529\n"
          ]
        }
      ],
      "source": [
        "epochs=10\n",
        "batch_size=32\n",
        "hidden=64\n",
        "n_layers=10\n",
        "heads=8\n",
        "\n",
        "transforms = T.Compose([\n",
        "    T.AddLaplacianEigenvectorPE(k=20, attr_name='eigens'),\n",
        "    #T.AddRandomWalkPE(walk_length=20, attr_name='walks')\n",
        "    ])\n",
        "\n",
        "dataset_train = ZINC(root=f'data/ZINC', split=\"train\", subset=True)\n",
        "dataset_val = ZINC(root=f'data/ZINC', split=\"val\", subset=True)\n",
        "dataset_test = ZINC(root=f'data/ZINC', split=\"test\", subset=True)\n",
        "pos_enc = AddLaplacianEigenvectorPE(k=50)\n",
        "dataset_train.data = pos_enc(dataset_train.data)\n",
        "dataset_val.data = pos_enc(dataset_val.data)\n",
        "dataset_test.data = pos_enc(dataset_test.data)\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size)\n",
        "val_loader = DataLoader(dataset_val, batch_size=batch_size)\n",
        "test_loader = DataLoader(dataset_test, batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "model = GraphTransformerNet(node_dim=dataset_train.num_features,\n",
        "                            edge_dim=dataset_train.num_edge_features,\n",
        "                            pe_dim=hidden,\n",
        "                            hidden_dim=hidden,\n",
        "                            num_layers=n_layers,\n",
        "                            num_heads=heads,\n",
        "                            dropout=0.1)\n",
        "\n",
        "print(f\"Train graphs: {len(dataset_train)}\")\n",
        "print(f\"Val graphs: {len(dataset_val)}\")\n",
        "print(f\"Test graphs: {len(dataset_test)}\\n\")\n",
        "print(model)\n",
        "total_params = count_parameters(model)\n",
        "print(\"Total de parámetros en el modelo:\", total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sbFNoiH6dIW_"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
        "                              min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "SVivJncweJ1f",
        "outputId": "2a192c02-fc96-49ea-d5c7-e16cc1d8330e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Graph Transformer:   0%|          | 0/10 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'GlobalStorage' object has no attribute 'laplacian_eigenvector_pe'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Graph Transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     train_loss, train_mae \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     val_loss, val_mae \u001b[38;5;241m=\u001b[39m test(val_loader)\n\u001b[0;32m      6\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
            "Cell \u001b[1;32mIn[2], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, loss_func)\u001b[0m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      8\u001b[0m out \u001b[38;5;241m=\u001b[39m model(x\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat(), edge_index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index, edge_attr\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m----> 9\u001b[0m             pe\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaplacian_eigenvector_pe\u001b[49m, batch\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out\u001b[38;5;241m.\u001b[39msqueeze(), data\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\graphgps\\lib\\site-packages\\torch_geometric\\data\\data.py:559\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\graphgps\\lib\\site-packages\\torch_geometric\\data\\storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'laplacian_eigenvector_pe'"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "for epoch in tqdm(range(epochs), desc=\"Training Graph Transformer\"):\n",
        "    train_loss, train_mae = train(epoch, criterion)\n",
        "    val_loss, val_mae = test(val_loader)\n",
        "    scheduler.step(val_loss)\n",
        "    print(f'Epoch: {epoch+1:03d}, Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f} | Train MAE: {train_mae:.4f}, Val MAE: {val_mae:.4f}')\n",
        "\n",
        "_, test_mae = test(test_loader)\n",
        "print(f'Test MAE: {test_mae:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IAzydX7EdrmO"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
